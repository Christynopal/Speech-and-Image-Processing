{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwbqeMHFSQBJ3Fex1cFjqo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Christynopal/Speech-and-Image-Processing/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load external data\n",
        "data_path = '/content/test.csv'\n",
        "df = pd.read_csv(data_path, encoding='latin-1')  # Update with the path to your dataset\n",
        "\n",
        "\n",
        "# Inspect unique values in the 'sentiment' column\n",
        "print(df['sentiment'].unique())\n",
        "\n",
        "# Map sentiment labels to integers\n",
        "label_mapping = {\n",
        "    'negative': 0,\n",
        "    'neutral': 1,\n",
        "    'positive': 2\n",
        "}\n",
        "df['sentiment'] = df['sentiment'].map(label_mapping)\n",
        "\n",
        "# Check for any non-mapped values\n",
        "print(df['sentiment'].unique())\n",
        "\n",
        "# Handle missing values\n",
        "df['text'] = df['text'].astype(str)  # Convert all texts to string type\n",
        "df['sentiment'] = df['sentiment'].fillna(0)  # Fill missing sentiment values with 0 (or appropriate value)\n",
        "\n",
        "# Check for any non-string values in the text column\n",
        "df['text'] = df['text'].apply(lambda x: x if isinstance(x, str) else '')\n",
        "\n",
        "texts = df['text'].values\n",
        "labels = df['sentiment'].values\n",
        "\n",
        "# Preprocess text data\n",
        "max_words = 20000  # Maximum number of words to consider in the vocabulary\n",
        "max_len = 300     # Maximum length of each sequence\n",
        "\n",
        "# Tokenizer to convert text to sequences of integers\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "# Convert text to sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Pad sequences to ensure they are all the same length\n",
        "X = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Convert labels to numpy array\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the GRU model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
        "model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(GRU(64)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))  # Output layer for multi-class classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Predict and get classification report\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)  # Convert probabilities to class labels\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "RSf2GCqrwlcD",
        "outputId": "7bf41d84-3f5f-49a6-b8da-7e27f5ff3dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neutral' 'positive' 'negative' nan]\n",
            "[ 1.  2.  0. nan]\n",
            "Epoch 1/20\n",
            "49/49 [==============================] - 15s 153ms/step - loss: 0.8769 - accuracy: 0.5310 - val_loss: 0.7919 - val_accuracy: 0.5642\n",
            "Epoch 2/20\n",
            "49/49 [==============================] - 6s 116ms/step - loss: 0.6542 - accuracy: 0.6822 - val_loss: 0.7200 - val_accuracy: 0.6472\n",
            "Epoch 3/20\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.3960 - accuracy: 0.8380 - val_loss: 0.7681 - val_accuracy: 0.6693\n",
            "Epoch 4/20\n",
            "49/49 [==============================] - 5s 97ms/step - loss: 0.2063 - accuracy: 0.9273 - val_loss: 0.9810 - val_accuracy: 0.6887\n",
            "Epoch 5/20\n",
            "49/49 [==============================] - 3s 71ms/step - loss: 0.0979 - accuracy: 0.9701 - val_loss: 1.1566 - val_accuracy: 0.6939\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.6871 - accuracy: 0.6625\n",
            "Accuracy: 0.6625129580497742\n",
            "31/31 [==============================] - 2s 18ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.73      0.78       484\n",
            "         1.0       0.47      0.54      0.50       268\n",
            "         2.0       0.61      0.65      0.63       211\n",
            "\n",
            "    accuracy                           0.66       963\n",
            "   macro avg       0.64      0.64      0.64       963\n",
            "weighted avg       0.68      0.66      0.67       963\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model after training\n",
        "model.save('sentiment_gru_model.h5')\n"
      ],
      "metadata": {
        "id": "bUytixzVvS20",
        "outputId": "16445f8b-5a8e-4565-f4fc-be9063ddccb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "# Load the trained model\n",
        "model = load_model('sentiment_gru_model.h5')\n"
      ],
      "metadata": {
        "id": "syrEVpNovZA6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text, tokenizer, max_len):\n",
        "    # Convert text to sequences of integers\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    # Pad sequences to ensure they are all the same length\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post', truncating='post')\n",
        "    return padded_sequence\n"
      ],
      "metadata": {
        "id": "do4vAxHiyAzv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text, model, tokenizer, max_len):\n",
        "    # Preprocess the text\n",
        "    preprocessed_text = preprocess_text(text, tokenizer, max_len)\n",
        "    # Make prediction\n",
        "    prediction = model.predict(preprocessed_text)\n",
        "    # Get the class with the highest probability\n",
        "    predicted_class = np.argmax(prediction, axis=-1)\n",
        "    return predicted_class[0]\n"
      ],
      "metadata": {
        "id": "80GzVoNFyCMW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('/content/sentiment_gru_model.h5')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p1aVnPHLyHoG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example new text for classification\n",
        "new_text = \"THAT IS BETTER\"\n",
        "\n",
        "# Predict sentiment\n",
        "predicted_class = predict_sentiment(new_text, model, tokenizer, max_len)\n",
        "\n",
        "# Map integer class back to sentiment label (adjust this mapping as needed)\n",
        "class_mapping = {\n",
        "    0: 'negative',\n",
        "    1: 'neutral',\n",
        "    2: 'positive'\n",
        "}\n",
        "\n",
        "predicted_sentiment = class_mapping.get(predicted_class, 'Unknown')\n",
        "print(f'The predicted sentiment is: {predicted_sentiment}')\n"
      ],
      "metadata": {
        "id": "C4uFyq6sydrb",
        "outputId": "9247ed58-6ddc-42fa-f139-a79b018a17b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n",
            "The predicted sentiment is: neutral\n"
          ]
        }
      ]
    }
  ]
}